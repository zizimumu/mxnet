{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  del sys.path[0]\n",
      "c:\\python3\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "import struct\n",
    "import logging\n",
    "import mxnet as mx\n",
    "import matplotlib.pyplot as plt # 这是常用的绘图库\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "def read_data(label_url, image_url): # 读入训练数据\n",
    "    with gzip.open(label_url) as flbl: # 打开标签文件\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8)) # 读入标签文件头\n",
    "        label = np.fromstring(flbl.read(), dtype=np.int8) # 读入标签内容\n",
    "    with gzip.open(image_url, 'rb') as fimg: # 打开图像文件\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16)) # 读入图像文件头，rows和cols都会是28\n",
    "        image = np.fromstring(fimg.read(), dtype=np.uint8) # 读入图像内容\n",
    "        image = image.reshape(len(label), 1, rows, cols) # 设置为正确的数组格式\n",
    "        image = image.astype(np.float32)/255.0 # 归一化为0到1区间\n",
    "    return (label, image)\n",
    "\n",
    "# 读入数据\n",
    "(train_lbl, train_img) = read_data('train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz')\n",
    "(val_lbl, val_img) = read_data('t10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz')\n",
    " \n",
    "batch_size = 32 # 批大小\n",
    "\n",
    "# 迭代器\n",
    "train_iter = mx.io.NDArrayIter(train_img, train_lbl, batch_size, shuffle=True)\n",
    "val_iter = mx.io.NDArrayIter(val_img, val_lbl, batch_size)  \n",
    "\n",
    "for i in range(10): # 输出前10个数字\n",
    "    plt.subplot(1,10,i+1) # 这里的语句可参见matplotlib库的介绍\n",
    "    plt.imshow(train_img[i].reshape(28,28), cmap='Greys_r') # 新版 matplotlib 需要这样 reshape\n",
    "    plt.axis('off')\n",
    "plt.show() # 显示图像\n",
    "print('label: %s' % (train_lbl[0:10],)) # 显示对应的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                                        Output Shape            Param #     Previous Layer                  \n",
      "========================================================================================================================\n",
      "data(null)                                          1x28x28                 0                                           \n",
      "________________________________________________________________________________________________________________________\n",
      "conv1(Convolution)                                  32x24x24                832         data                            \n",
      "________________________________________________________________________________________________________________________\n",
      "bn1(BatchNorm)                                      32x24x24                64          conv1                           \n",
      "________________________________________________________________________________________________________________________\n",
      "act1(Activation)                                    32x24x24                0           bn1                             \n",
      "________________________________________________________________________________________________________________________\n",
      "pool1(Pooling)                                      32x11x11                0           act1                            \n",
      "________________________________________________________________________________________________________________________\n",
      "conv2(Convolution)                                  64x7x7                  51264       pool1                           \n",
      "________________________________________________________________________________________________________________________\n",
      "bn2(BatchNorm)                                      64x7x7                  128         conv2                           \n",
      "________________________________________________________________________________________________________________________\n",
      "act2(Activation)                                    64x7x7                  0           bn2                             \n",
      "________________________________________________________________________________________________________________________\n",
      "pool2(Pooling)                                      64x3x3                  0           act2                            \n",
      "________________________________________________________________________________________________________________________\n",
      "conv3(Convolution)                                  10x1x1                  5770        pool2                           \n",
      "________________________________________________________________________________________________________________________\n",
      "pool3(Pooling)                                      10x1x1                  0           conv3                           \n",
      "________________________________________________________________________________________________________________________\n",
      "flatten(Flatten)                                    10                      0           pool3                           \n",
      "________________________________________________________________________________________________________________________\n",
      "softmax(SoftmaxOutput)                              10                      0           flatten                         \n",
      "========================================================================================================================\n",
      "Total params: 58058\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data = mx.symbol.Variable('data')\n",
    "\n",
    "# 第1个卷积层，以及相应的BN和非线性，有32个5*5卷积\n",
    "conv1 = mx.sym.Convolution(data=data, name=\"conv1\", kernel=(5,5), num_filter=32)\n",
    "# 对于BN层我们往往会加上fix_gamma=False这个参数\n",
    "bn1 = mx.sym.BatchNorm(data=conv1, name=\"bn1\", fix_gamma=False)\n",
    "act1 = mx.sym.Activation(data=bn1, name=\"act1\", act_type=\"relu\")\n",
    "# 第1个池化层，使用了3*3大小和2*2步长\n",
    "pool1 = mx.sym.Pooling(data=act1, name=\"pool1\", pool_type=\"max\", kernel=(3,3), stride=(2,2))\n",
    "\n",
    "# 第2个卷积层，以及相应的BN和非线性，有64个5*5卷积\n",
    "conv2 = mx.sym.Convolution(data=pool1, name=\"conv2\", kernel=(5,5), num_filter=64)\n",
    "bn2 = mx.sym.BatchNorm(data=conv2, name=\"bn2\", fix_gamma=False)\n",
    "act2 = mx.sym.Activation(data=bn2, name=\"act2\", act_type=\"relu\")\n",
    "# 第2个池化层，使用了3*3大小和2*2步长\n",
    "pool2 = mx.sym.Pooling(data=act2, name=\"pool2\", pool_type=\"max\", kernel=(3,3), stride=(2,2))\n",
    "\n",
    "# 第3个卷积层，有10个3*3卷积\n",
    "conv3 = mx.sym.Convolution(data=pool2, name=\"conv3\", kernel=(3,3), num_filter=10)\n",
    "# 第3个池化层，这里设置global_pool进行全局池化，会忽略kernel的值\n",
    "pool3 = mx.sym.Pooling(data=conv3, name=\"pool3\", global_pool=True, pool_type=\"avg\", kernel=(1,1))\n",
    "# 将图像摊平，这里的效果是将10张1*1的图像摊平，因此得到10个数\n",
    "flatten = mx.sym.Flatten(data=pool3, name=\"flatten\")\n",
    "# SoftMax层，将10个数变为10个分类的概率\n",
    "net = mx.sym.SoftmaxOutput(data=flatten, name='softmax')\n",
    "\n",
    "\n",
    "# 我们将调用MXNet中的viz库，需要先告知MXNet输入数据的格式\n",
    "shape = {\"data\" : (batch_size, 1, 28, 28)}\n",
    "mx.viz.print_summary(symbol=net, shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mx.viz.plot_network(symbol=net, shape=shape).view() # 注意需安装 Graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_iter.reset() # 将val_iter重置，保证是从头开始提供数据\n",
    "# 前向传播，用next()进行val_iter的迭代，每次调用可得到一个batch的数据\n",
    "#module.forward(val_iter.next(), is_train=False) \n",
    "#out = module.get_outputs()[0].asnumpy() # 得到输出\n",
    "# 将输出做一些美观处理\n",
    "#print(zip(out.argmax(axis=1), out.max(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[0] Train-accuracy=0.973133\n",
      "INFO:root:Epoch[0] Time cost=93.813\n",
      "INFO:root:Saved checkpoint to \"MNIST_symb.params-0001.params\"\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.989716\n",
      "INFO:root:Update[1876]: Change learning rate to 2.70000e-02\n",
      "INFO:root:Epoch[1] Train-accuracy=0.990300\n",
      "INFO:root:Epoch[1] Time cost=93.921\n",
      "INFO:root:Saved checkpoint to \"MNIST_symb.params-0002.params\"\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.992113\n",
      "INFO:root:Update[3751]: Change learning rate to 2.43000e-02\n",
      "INFO:root:Epoch[2] Train-accuracy=0.993200\n",
      "INFO:root:Epoch[2] Time cost=101.545\n",
      "INFO:root:Saved checkpoint to \"MNIST_symb.params-0003.params\"\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.991913\n",
      "INFO:root:Update[5626]: Change learning rate to 2.18700e-02\n",
      "INFO:root:Epoch[3] Train-accuracy=0.994550\n",
      "INFO:root:Epoch[3] Time cost=111.691\n",
      "INFO:root:Saved checkpoint to \"MNIST_symb.params-0004.params\"\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.992812\n",
      "INFO:root:Update[7501]: Change learning rate to 1.96830e-02\n",
      "INFO:root:Epoch[4] Train-accuracy=0.995967\n",
      "INFO:root:Epoch[4] Time cost=99.254\n",
      "INFO:root:Saved checkpoint to \"MNIST_symb.params-0005.params\"\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.992612\n",
      "INFO:root:Update[9376]: Change learning rate to 1.77147e-02\n",
      "INFO:root:Epoch[5] Train-accuracy=0.996900\n",
      "INFO:root:Epoch[5] Time cost=99.029\n",
      "INFO:root:Saved checkpoint to \"MNIST_symb.params-0006.params\"\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.993510\n",
      "INFO:root:Update[11251]: Change learning rate to 1.59432e-02\n",
      "INFO:root:Epoch[6] Train-accuracy=0.997667\n",
      "INFO:root:Epoch[6] Time cost=103.693\n",
      "INFO:root:Saved checkpoint to \"MNIST_symb.params-0007.params\"\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.993411\n",
      "INFO:root:Update[13126]: Change learning rate to 1.43489e-02\n",
      "INFO:root:Epoch[7] Train-accuracy=0.998517\n",
      "INFO:root:Epoch[7] Time cost=95.990\n",
      "INFO:root:Saved checkpoint to \"MNIST_symb.params-0008.params\"\n",
      "INFO:root:Epoch[7] Validation-accuracy=0.993311\n",
      "INFO:root:Update[15001]: Change learning rate to 1.29140e-02\n",
      "INFO:root:Epoch[8] Train-accuracy=0.998650\n",
      "INFO:root:Epoch[8] Time cost=95.064\n",
      "INFO:root:Saved checkpoint to \"MNIST_symb.params-0009.params\"\n",
      "INFO:root:Epoch[8] Validation-accuracy=0.993411\n",
      "INFO:root:Update[16876]: Change learning rate to 1.16226e-02\n",
      "INFO:root:Epoch[9] Train-accuracy=0.998950\n",
      "INFO:root:Epoch[9] Time cost=92.513\n",
      "INFO:root:Saved checkpoint to \"MNIST_symb.params-0010.params\"\n",
      "INFO:root:Epoch[9] Validation-accuracy=0.993710\n"
     ]
    }
   ],
   "source": [
    "# 由于训练数据量较大，这里采用了GPU，若读者没有GPU，可修改为CPU\n",
    "#module = mx.mod.Module(symbol=net, context=mx.gpu(0))\n",
    "module = mx.mod.Module(symbol=net)\n",
    "\n",
    "model_prefix = 'MNIST_symb.params'\n",
    "checkpoint = mx.callback.do_checkpoint(model_prefix)\n",
    "\n",
    "module.fit(\n",
    "    train_iter,\n",
    "    eval_data=val_iter,\n",
    "    optimizer = 'sgd', \n",
    "# 采用0.03的初始学习速率，并在每60000个样本后（即每1个epoch后）将学习速率缩减为之前的0.9倍\n",
    "    optimizer_params = {'learning_rate' : 0.03, 'lr_scheduler' : mx.lr_scheduler.FactorScheduler(step=60000/batch_size, factor=0.9)},\n",
    "    num_epoch = 10,     \n",
    "    batch_end_callback = mx.callback.Speedometer(batch_size, 60000/batch_size),\n",
    "    epoch_end_callback = checkpoint,\n",
    ")\n",
    "\n",
    "#module._symbol.save('sysbol.json')\n",
    "#module.save_params(\"sysbol.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(val_img[0].reshape(28,28), cmap='Greys_r') # 新版 matplotlib 需要这样 reshape\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(val_lbl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAElElEQVR4nO3dvWpUWwCG4dlHi4CQwiIQwZ82qBeQ1iqNIHgFYmXnDVhYWApJ7T2IhaVYWQhehCkiWFiJoGCxT3eqzDrkd96B5ynnY3Q3LwuymJlpnucF0PPPqh8AOJ44IUqcECVOiBInRF0djdM0+VMuXLB5nqfjXndyQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTooY/AcjF+PHjx9Lt+vXrw/dubm4O91+/fp3qmehxckKUOCFKnBAlTogSJ0SJE6LECVHuOVdgnudTbYvFYvH06dPhfnBwcKpnosfJCVHihChxQpQ4IUqcECVOiBInRE2je7VpmsaXbpzK169fl263bt0607995cqVM72fyzfP83Tc605OiBInRIkTosQJUeKEKHFClKuUFXjy5MnS7eXLl8P33rhxY7jfvn17uH/79m24c/lcpcCaESdEiROixAlR4oQocUKUOCHKPWfM6A50sVgs3rx5M9zfv38/3B89enTiZ+JiueeENSNOiBInRIkTosQJUeKEKHFClJ8AjLlz585wn6Zjr8T+s7e3d45Pwyo5OSFKnBAlTogSJ0SJE6LECVHihCif54w5Ojoa7tvb28P979+/w31jY+PEz8TF8nlOWDPihChxQpQ4IUqcECVOiBInRPk8Z8y7d++G+7Nnzy7pSVg1JydEiROixAlR4oQocUKUOCHKVUrMzs7Oqh+BCCcnRIkTosQJUeKEKHFClDghSpwQ5asxY37+/Dncr127Ntz/7ycCX7x4MdxfvXo13Dl/vhoT1ow4IUqcECVOiBInRIkTosQJUe45Yx48eDDc9/f3h/v9+/eH++fPn4f77u7ucOf8ueeENSNOiBInRIkTosQJUeKEKHFClO+tjfn48eNw//Dhw3C/d+/ecL979+6Jn4nVcHJClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROipnmel4/TtHxkJb5//z7ct7a2hvvv37+H++gnAg8PD4fv5XTmeZ6Oe93JCVHihChxQpQ4IUqcECVOiBInRF1d9QNwMn/+/DnT+zc2Nob748ePl26vX78+0//NyTg5IUqcECVOiBInRIkTosQJUa5S1szbt2+H+/Pnzy/pSbhoTk6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IcrnOdfMp0+fhvvDhw+H+82bN4f7ly9fTvxMXAwnJ0SJE6LECVHihChxQpQ4IUqcEDXN87x8nKblI3Au5nmejnvdyQlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlToga/gQgsDpOTogSJ0SJE6LECVHihChxQtS/O+yV6m3HwxoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_iter.reset()\n",
    "for i in range(0,15):\n",
    "    # 如前所述，每次调用val_iter.next()都会得到一个batch的数据 \n",
    "    module.forward(val_iter.next(), is_train=False)\n",
    "    out = module.get_outputs()[0].asnumpy().argmax(axis=1)\n",
    "    for j in range(0,len(out)):\n",
    "        if out[j] != val_lbl[i*batch_size + j]: # 是否错误识别？\n",
    "            print(out[j], val_lbl[j]) # 输出错误的情况\n",
    "            plt.imshow(val_img[j].reshape(28,28), cmap='Greys_r')\n",
    "            plt.axis('off')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.00000001 0.00000007 0.00000019 0.         0.\n",
      "  0.         0.9999988  0.         0.00000099]]\n"
     ]
    }
   ],
   "source": [
    "# 定义一个简单数据结构，方便后续 module 读取数据\n",
    "from collections import namedtuple\n",
    "MyBatch = namedtuple('MyBatch', ['data', 'label'])\n",
    "\n",
    "# 对于不熟悉 namedtuple 的朋友，这里举例说明 namedtuple 的运作方式：\n",
    "# 如果此时执行 MyBatchExample = MyBatch('abc', 'def')\n",
    "# 那么 print(MyBatchExample.data) 就会输出 'abc'\n",
    "# 而 print(MyBatchExample.label) 就会输出 'def'\n",
    "\n",
    "# 将 module 重新绑定为批大小为1\n",
    "new_batch_size = 1\n",
    "module.bind(data_shapes=[('data', (new_batch_size, 1, 28, 28))], label_shapes=[('softmax_label', (new_batch_size,))], force_rebind=True, for_training=False) # 设置force_rebind为True，说明是在重新绑定；设置for_training为False，说明只作前向传播\n",
    "\n",
    "# 这里的数据使用val_img的第1张。我们也可送入自己生成的数据\n",
    "# 这里将MyBatch的第2个参数设为None，因为它对应标签，而运行网络不需要标签\n",
    "MyBatchData = MyBatch([mx.nd.array(val_img[0].reshape(1, 1, 28, 28).astype(np.float32))], None)\n",
    "\n",
    "# 运行网络，module 会读取 MyBatchData.data 和 MyBatchData.label\n",
    "module.forward(MyBatchData) \n",
    "# 关闭 print 的科学计数法显示，让结果更美观\n",
    "np.set_printoptions(suppress=True)\n",
    "# 输出网络运行结果\n",
    "print(module.get_outputs()[0].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
